This project tackles the challenge of semi-supervised image classification, aiming to leverage the power of unlabeled data alongside a limited set of labeled examples. We focus on the MNIST handwritten digit classification task, where only a portion of the training images possess ground truth labels. To achieve this, we propose a novel methodology that combines K-means clustering with an encoder model.

The encoder model extracts informative features from the input images. These features are then utilized for two purposes: supervised learning and unsupervised clustering. For the labeled data, a classification head is attached to the encoder's output, trained with cross-entropy loss. Simultaneously, the unlabeled data is fed through the encoder, and its features are clustered using the K-means algorithm. This clustering loss is incorporated into the overall training objective, encouraging the encoder to learn feature representations that not only distinguish labeled classes but also exhibit inherent structure within the unlabeled data. By effectively combining these supervised and unsupervised learning components, our approach aims to improve classification performance even when labeled data is scarce.