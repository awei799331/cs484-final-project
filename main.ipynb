{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CS 484 Final Project\n",
    "\n",
    "Alexander Wei, a6wei@uwaterloo.ca, 20836214\n",
    "Kaiz Nanji\n",
    "\n",
    "Project #5\n",
    "Semi-supervised image classification: assuming that only M out of N images in the traingin data have ground truth labels,\n",
    "design and implement a weakly supervsied training of classification network that can benefit from unlabeled examples in\n",
    "the training dataset(e.g. MNIST or CIFAR-10, but you need to ignore labels on a subset of training examples).You should\n",
    "demonstrate how the performance changes as M gets progressively smaller. While you can use any well-motivated ideas, one\n",
    "basic approach could be to combine cross-entropy on labeled points with (unsupervised) K-means clustering loss over deep\n",
    "features (e.g. in the last layer before the linear classifier). It is also advisable to use augmentation (a loss\n",
    "enforcing consistent labeling of augmented training examples). You can also explore Mutual Information loss function\n",
    "formulated in Bridle & MacKay \"Unsupervised Classifiers, Mutual Information and Phantom Targets\", NIPS 1991. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import *\n",
    "from src.utils import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks the filepath \"./data/MNIST/raw\" for the dataset. If not found, downloads the dataset\n",
    "\"\"\"\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "mnist_train, mnist_test = download(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase TRAIN_BATCH_SIZE if you are using GPU to speed up training. \n",
    "# When batch size changes, the learning rate may also need to be adjusted. \n",
    "# Note that batch size maybe limited by your GPU memory, so adjust if you get \"run out of GPU memory\" error.\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "\n",
    "# If you are NOT using Windows, set NUM_WORKERS to anything you want, e.g. NUM_WORKERS = 4,\n",
    "# but Windows has issues with multi-process dataloaders, so NUM_WORKERS must be 0 for Windows.\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=TRAIN_BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "val_loader = DataLoader(mnist_test, batch_size=1, num_workers=NUM_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gmm = MyGaussianMixture()\n",
    "\n",
    "my_loss_function = MyLossFunction(my_gmm)\n",
    "my_loss_function = my_loss_function.to(device)\n",
    "\n",
    "my_model = MyModel(my_loss_function, my_gmm)\n",
    "my_model = my_model.to(device)\n",
    "\n",
    "sgd_optimizer = get_optimizer(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_graph = []\n",
    "\n",
    "train_model(my_model, device, train_loader, sgd_optimizer, loss_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
